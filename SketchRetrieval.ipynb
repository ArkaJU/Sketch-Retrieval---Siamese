{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wk_g0iEgXk3g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkBa5hyKXk34"
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path)/255\n",
    "    return cv2.resize(img, (100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NKWbl-wXk4V"
   },
   "outputs": [],
   "source": [
    "def mynet(inp, reuse=False):\n",
    "    with tf.variable_scope(\"model\"):\n",
    "        print(inp.shape)\n",
    "        with tf.variable_scope(\"conv1\") as scope:\n",
    "            net = tf.contrib.layers.conv2d(inp, 32, 15, \n",
    "                                        stride=1,\n",
    "                                        activation_fn=tf.nn.relu, \n",
    "                                        padding='VALID',\n",
    "                                        weights_initializer=tf.keras.initializers.he_normal(),\n",
    "                                        scope=scope,\n",
    "                                        reuse=reuse)\n",
    "            \n",
    "            print(net.shape)\n",
    "            \n",
    "            net = tf.contrib.layers.max_pool2d(net, kernel_size=2, stride=2)\n",
    "                                    \n",
    "            net = tf.contrib.layers.batch_norm(net, reuse=reuse, scope=scope)\n",
    "            \n",
    "            print(net.shape)\n",
    "            \n",
    "\n",
    "        with tf.variable_scope(\"conv2\") as scope:\n",
    "            net = tf.contrib.layers.conv2d(net, 64, 8,\n",
    "                                        stride=1,\n",
    "                                        activation_fn=tf.nn.relu, \n",
    "                                        padding='VALID',\n",
    "                                        weights_initializer=tf.keras.initializers.he_normal(),\n",
    "                                        scope=scope,\n",
    "                                        reuse=reuse)\n",
    "            \n",
    "            print(net.shape)\n",
    "            \n",
    "            net = tf.contrib.layers.max_pool2d(net, kernel_size=3, stride=3)\n",
    "                    \n",
    "            net = tf.contrib.layers.batch_norm(net, reuse=reuse, scope=scope)\n",
    "            \n",
    "            print(net.shape)\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"conv3\") as scope:\n",
    "            net = tf.contrib.layers.conv2d(net, 256, 5, \n",
    "                                        stride=1,\n",
    "                                        activation_fn=tf.nn.relu,\n",
    "                                        padding='VALID',\n",
    "                                        weights_initializer=tf.keras.initializers.he_normal(),\n",
    "                                        scope=scope,\n",
    "                                        reuse=reuse)\n",
    "            \n",
    "            print(net.shape)\n",
    "            \n",
    "            net = tf.contrib.layers.max_pool2d(net, kernel_size=2, stride=2)\n",
    "\n",
    "            net = tf.contrib.layers.batch_norm(net, reuse=reuse, scope=scope)\n",
    "            \n",
    "            print(net.shape)\n",
    "\n",
    "        \n",
    "        with tf.variable_scope(\"fc1\") as scope:\n",
    "            net = tf.contrib.layers.flatten(net)\n",
    "            print(net.shape)\n",
    "        \n",
    "        with tf.variable_scope(\"fc2\") as scope:\n",
    "            net = tf.contrib.layers.fully_connected(net, 64, \n",
    "                                                    activation_fn=tf.nn.relu, \n",
    "                                                    reuse=reuse, \n",
    "                                                    scope=scope)\n",
    "            print(net.shape)\n",
    "        \n",
    "        \n",
    "    return net\n",
    "\n",
    "\n",
    "def contrastive_loss(model1, model2, y, margin):\n",
    "    with tf.name_scope(\"contrastive-loss\"):\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.pow(model1-model2, 2), 1, keepdims=True))\n",
    "        tmp = y * tf.square(d)    \n",
    "        tmp2 = (1 - y) * tf.square(tf.maximum((margin - d),0))\n",
    "    return tf.reduce_mean(tmp + tmp2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCyCx7aqXk4j",
    "outputId": "252cc6da-0254-4620-bc78-8c97b04229c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 100, 3)\n",
      "(?, 86, 86, 32)\n",
      "(?, 43, 43, 32)\n",
      "(?, 36, 36, 64)\n",
      "(?, 12, 12, 64)\n",
      "(?, 8, 8, 256)\n",
      "(?, 4, 4, 256)\n",
      "(?, 4096)\n",
      "(?, 64)\n",
      "(?, 100, 100, 3)\n",
      "(?, 86, 86, 32)\n",
      "(?, 43, 43, 32)\n",
      "(?, 36, 36, 64)\n",
      "(?, 12, 12, 64)\n",
      "(?, 8, 8, 256)\n",
      "(?, 4, 4, 256)\n",
      "(?, 4096)\n",
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "left = tf.placeholder(tf.float32, [None, 100, 100, 3], name='left')\n",
    "right = tf.placeholder(tf.float32, [None, 100, 100, 3], name='right')\n",
    "\n",
    "label = tf.placeholder(tf.int32, [None, 1], name='label') # 1 if same, 0 if different\n",
    "label = tf.to_float(label)\n",
    "\n",
    "margin = 1\n",
    "\n",
    "left_output = mynet(left, reuse=False)\n",
    "right_output = mynet(right, reuse=True)\n",
    "\n",
    "loss = contrastive_loss(left_output, right_output, label, margin)\n",
    "optim = tf.train.AdamOptimizer(0.0005).minimize(loss)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/Sketchy/\"\n",
    "photo_path = os.path.join(dataset_path, 'photo/')\n",
    "sketch_path = os.path.join(dataset_path, 'sketch/')\n",
    "\n",
    "def get_dict():\n",
    "    \n",
    "    photo_dictionary = {}\n",
    "\n",
    "    for category in os.listdir(photo_path):\n",
    "        category_path = os.path.join(photo_path, category)\n",
    "\n",
    "        photo_dictionary[category] = os.listdir(category_path)\n",
    "\n",
    "    sketch_dictionary = {}\n",
    "\n",
    "    for category in os.listdir(sketch_path):\n",
    "        category_path = os.path.join(sketch_path, category)\n",
    "\n",
    "        sketch_dictionary[category] = os.listdir(category_path) \n",
    "    \n",
    "    return photo_dictionary, sketch_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtufaRyVXk4H"
   },
   "outputs": [],
   "source": [
    "def get_batch(photo_dictionary, sketch_dictionary):\n",
    "    \n",
    "    \n",
    "    l = []\n",
    "    p_ = []\n",
    "    s_ = []\n",
    "\n",
    "    for _ in range(128): \n",
    "\n",
    "        if np.random.uniform() >= 0.5:\n",
    "\n",
    "            photo_class = np.random.choice(list(photo_dictionary))\n",
    "            photo = np.random.choice(photo_dictionary[photo_class])\n",
    "            photo_dictionary[photo_class].remove(photo)\n",
    "            p = photo_class + '/' + photo\n",
    "\n",
    "            sketch_class = photo_class\n",
    "            sketch = np.random.choice(sketch_dictionary[sketch_class])\n",
    "            sketch_dictionary[sketch_class].remove(sketch)\n",
    "            s = sketch_class + '/' + sketch\n",
    "            label = 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            x = list(photo_dictionary)\n",
    "            photo_class = np.random.choice(x)\n",
    "            photo = np.random.choice(photo_dictionary[photo_class])\n",
    "            photo_dictionary[photo_class].remove(photo)\n",
    "            p = photo_class + '/' + photo\n",
    "            x.remove(photo_class)\n",
    "\n",
    "            sketch_class = np.random.choice(x)\n",
    "            sketch = np.random.choice(sketch_dictionary[sketch_class])\n",
    "            sketch_dictionary[sketch_class].remove(sketch)\n",
    "            s = sketch_class + '/' + sketch\n",
    "            label = 0\n",
    "\n",
    "        p_.append(os.path.join(dataset_path, 'photo/', p))\n",
    "        s_.append(os.path.join(dataset_path, 'sketch/', s))\n",
    "        l.append(label)\n",
    "    \n",
    "    images = np.array([load_img(i) for i in p_])\n",
    "    sketches = np.array([load_img(i) for i in s_])\n",
    "    labels = np.array(l)\n",
    "\n",
    "    return images, sketches, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkXfLemtXk40",
    "outputId": "3645b9b9-d2af-4c42-821e-e652da940353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_paths = []\n",
    "for category in os.listdir(photo_path):\n",
    "    category_path = os.path.join(photo_path, category + '/')\n",
    "    image_paths = np.random.choice(os.listdir(category_path), size=20, replace=False)\n",
    "    for i in range(20):\n",
    "        test_image_paths.append(category_path + image_paths[i])\n",
    "np.random.shuffle(test_image_paths)\n",
    "len(np.unique(test_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsubqiv0Xk5D",
    "outputId": "f54ac24e-77aa-4fd8-a98d-35d68641fefb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/Sketchy/sketch/lion/n02129165_12039-2.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sketch_path = sketch_path + np.random.choice(os.listdir(sketch_path)) \n",
    "test_sketch_path = test_sketch_path + '/' + np.random.choice(os.listdir(test_sketch_path))\n",
    "test_sketch_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98rVKbjJXk5d",
    "outputId": "fae4936d-6af0-416c-9509-e2ab79a3d9b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 100, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sketch = load_img(test_sketch_path)\n",
    "test_sketch = np.expand_dims(test_sketch, 0)\n",
    "test_sketch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LzbcZNsXk54"
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for path in test_image_paths:\n",
    "    test_images.append(load_img(path))\n",
    "test_images = np.array(test_images)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOCZmxEYXk6M"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(test_sketch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOw35XSMXk6e"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1000000):\n",
    "    photo_dictionary, sketch_dictionary = get_dict()\n",
    "    p_batch, s_batch, lab_batch = get_batch(photo_dictionary, sketch_dictionary)\n",
    "    lab_batch = lab_batch.reshape(-1, 1)\n",
    "    [_, loss_] = sess.run([optim,loss], {left: p_batch, right: s_batch, label:lab_batch})\n",
    "    \n",
    "    \n",
    "    if epoch%100==0:\n",
    "        \n",
    "        sketch_repr = sess.run([left_output], {left: test_sketch})\n",
    "        sketch_repr = np.squeeze(np.array(sketch_repr), 1)\n",
    "        print(sketch_repr.shape)\n",
    "        sketch_representations = np.tile(sketch_repr, 2496).reshape(2496, 64)\n",
    "        print(sketch_representations.shape)\n",
    "        \n",
    "        batch_size = 8\n",
    "        n_batches = len(test_images) // batch_size\n",
    "        image_representations = []\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            img_repr = sess.run([left_output], {left: test_images[i*batch_size : (i+1)*batch_size]})\n",
    "            img_repr = np.squeeze(np.array(img_repr), 0)\n",
    "            image_representations.append(img_repr)\n",
    "        image_representations = np.vstack(image_representations)\n",
    "\n",
    "        diff = np.sqrt(np.mean((sketch_representations - image_representations)**2, -1))\n",
    "        top_k = np.argsort(diff)[:5]\n",
    "\n",
    "        print ('##' + str(epoch) + ' : loss == ' + str(loss_))\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i in range(5):    \n",
    "            img = mpimg.imread(test_image_paths[top_k[i]])\n",
    "            plt.subplot(1, 5, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SketchRetrieval.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
